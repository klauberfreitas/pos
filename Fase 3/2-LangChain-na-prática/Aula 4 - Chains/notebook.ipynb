{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain_openai pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.memory import SimpleMemory\n",
    "from datetime import datetime\n",
    "\n",
    "llm = OpenAI()\n",
    "\n",
    "template_rapper: str = \"\"\"Você é um compositor de rap renomado. Sua missão é criar uma letra de rap\n",
    "inspirada no tema fornecido.\n",
    "\n",
    "Tema da música:\n",
    "{input}\"\"\"\n",
    "\n",
    "prompt_template_rapper: PromptTemplate = PromptTemplate(\n",
    "   input_variables=[\"input\"], template=template_rapper)\n",
    "\n",
    "cadeia_rapper: LLMChain = LLMChain(\n",
    "   llm=llm, output_key=\"letra\", prompt=prompt_template_rapper)\n",
    "\n",
    "template_verificador: str = \"\"\"Você é responsável por revisar letras de rap. Seu trabalho é verificar se as letras contêm\n",
    "algum conteúdo violento ou linguagem inadequada.\n",
    "\n",
    "Por favor, responda no formato de um dicionário Python:\n",
    "letra: a letra recebida\n",
    "Palavras_violentas: Verdadeiro ou Falso\n",
    "\n",
    "Aqui está a letra a ser verificada:\n",
    "{letra}\"\"\"\n",
    "\n",
    "prompt_template_verificador: PromptTemplate = PromptTemplate(\n",
    "   input_variables=[\"letra\"], template=template_verificador)\n",
    "\n",
    "cadeia_verificador: LLMChain = LLMChain(\n",
    "   llm=llm, output_key=\"letra_verificada\", prompt=prompt_template_verificador)\n",
    "\n",
    "template_final: str = \"\"\"Você é responsável pela verificação final das letras de rap. Seu trabalho é garantir que\n",
    "a letra revisada esteja dentro dos padrões aceitáveis.\n",
    "\n",
    "Sua resposta final deve ser no formato de dicionário Python:\n",
    "letra: a letra recebida\n",
    "Data e hora da verificação: {data_hora_verificacao}\n",
    "Verificada por um humano: {verificada_por_humano}\n",
    "\n",
    "Aqui está a letra revisada:\n",
    "{letra_verificada}\"\"\"\n",
    "\n",
    "# Criando o template de prompt para a revisão final\n",
    "prompt_template_final: PromptTemplate = PromptTemplate(\n",
    "   input_variables=[\"letra_verificada\", \"data_hora_verificacao\", \"verificada_por_humano\"],\n",
    "   template=template_final\n",
    ")\n",
    "\n",
    "cadeia_final: LLMChain = LLMChain(\n",
    "   llm=llm, output_key=\"saida_final\", prompt=prompt_template_final)\n",
    "\n",
    "cadeia_sequencial: SequentialChain = SequentialChain(\n",
    "   memory=SimpleMemory(memories={\n",
    "                       \"data_hora_verificacao\": str(datetime.utcnow()), \"verificada_por_humano\": \"Falso\"}),\n",
    "   chains=[cadeia_rapper, cadeia_verificador, cadeia_final],\n",
    "   input_variables=[\"input\"],\n",
    "   output_variables=[\"saida_final\"],\n",
    "   verbose=True)\n",
    "\n",
    "resultado = cadeia_sequencial.run(input=\"violência nas ruas\")\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from typing import Literal\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "prompt_acoes = ChatPromptTemplate.from_messages(\n",
    "   [\n",
    "       (\"system\", \"Você é um especialista em investimentos em ações.\"),\n",
    "       (\"human\", \"{query}\"),\n",
    "   ]\n",
    ")\n",
    "\n",
    "prompt_renda_fixa = ChatPromptTemplate.from_messages(\n",
    "   [\n",
    "       (\"system\", \"Você é um especialista em investimentos de renda fixa.\"),\n",
    "       (\"human\", \"{query}\"),\n",
    "   ]\n",
    ")\n",
    "\n",
    "chain_acoes = prompt_acoes | llm | StrOutputParser()\n",
    "chain_renda_fixa = prompt_renda_fixa | llm | StrOutputParser()\n",
    "\n",
    "route_system = \"Roteie a pergunta do usuário para o especialista em ações ou renda fixa.\"\n",
    "route_prompt = ChatPromptTemplate.from_messages(\n",
    "   [\n",
    "       (\"system\", route_system),\n",
    "       (\"human\", \"{query}\"),\n",
    "   ]\n",
    ")\n",
    "\n",
    "class RouteQuery(TypedDict):\n",
    "   destination: Literal[\"acoes\", \"renda_fixa\"]\n",
    "\n",
    "route_chain = (\n",
    "   route_prompt\n",
    "   | llm.with_structured_output(RouteQuery)\n",
    "   | itemgetter(\"destination\")\n",
    ")\n",
    "\n",
    "chain = {\n",
    "   \"destination\": route_chain,\n",
    "   \"query\": lambda x: x[\"query\"],\n",
    "} | RunnableLambda(\n",
    "   lambda x: chain_acoes if x[\"destination\"] == \"acoes\" else chain_renda_fixa,\n",
    ")\n",
    "\n",
    "resultado = chain.invoke({\"query\": \"Quais são os riscos de investir em ações de tecnologia?\"})\n",
    "print(resultado)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
